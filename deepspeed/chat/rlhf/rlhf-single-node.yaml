apiVersion: batch.tensorstack.dev/v1beta1
kind: DeepSpeedJob
metadata:
  name: rlhf-single-node
spec:
  scheduler:
    t9kScheduler:
      queue: mlperf
      priority: 50
  config:
    slotsPerWorker: 4
    otherArgs: ["--master_port", "12346"]
    run:
      python: [
        "./examples/deepspeed/chat/rlhf/main.py",
        "--data_path", "./datasets/Dahoas/rm-static",
        "--data_split", "2,4,4",
        "--actor_model_name_or_path", "./output/single-node/actor-models/llama2-7b",
        "--critic_model_name_or_path", "./output/single-node/reward-models/llama2-7b",
        "--num_padding_at_beginning", "1",
        "--per_device_generation_batch_size", "1",
        "--per_device_training_batch_size", "1",
        "--generation_batches", "1",
        "--ppo_epochs", "1",
        "--max_answer_seq_len", "256",
        "--max_prompt_seq_len", "256",
        "--actor_learning_rate", "9.65e-6",
        "--critic_learning_rate", "5e-6",
        "--actor_weight_decay", "0.1",
        "--critic_weight_decay", "0.1",
        "--num_train_epochs", "1",
        "--lr_scheduler_type", "cosine",
        "--gradient_accumulation_steps", "1",
        "--actor_gradient_checkpointing",
        "--critic_gradient_checkpointing",
        "--offload_reference_model",
        "--disable_actor_dropout",
        "--num_warmup_steps", "100",
        "--deepspeed",
        "--seed", "1234",
        "--actor_zero_stage", "3",
        "--critic_zero_stage", "3",
        "--enable_mixed_precision_lora",
        "--actor_lora_dim", "64",
        "--critic_lora_dim", "64",
        "--actor_lora_module_name", "layers.",
        "--critic_lora_module_name", "layers.",
        "--output_dir", "./output/single-node/ppo-models/llama2-7b",
        "--enable_tensorboard",
        "--tensorboard_path", "./output/single-node/ppo-logs/llama2-7b",
      ]
  worker:
    replicas: 1
    template:
      spec:
        containers:
          - name: worker
            workingDir: /t9k/mnt/
            image: tsz.io/xyx/deepspeed:chat-0.10.2-2
            securityContext:
              capabilities:
                add: [ "IPC_LOCK" ]
            resources:
              requests:
                cpu: 8
                memory: 256Gi
                nvidia.com/gpu: 4
              limits:
                cpu: 16
                memory: 512Gi
                nvidia.com/gpu: 4
            volumeMounts:
              - mountPath: /t9k/mnt
                name: code
              - mountPath: /dev/shm
                name: dshm
        volumes:
          - name: code
            persistentVolumeClaim:
              claimName: gpt
          - name: dshm
            emptyDir:
              medium: Memory
