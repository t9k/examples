apiVersion: apps/v1
kind: Deployment
metadata:
  name: search
spec:
  replicas: 1
  selector:
    matchLabels:
      app: search
  template:
    metadata:
      labels:
        app: search
    spec:
      containers:
      - name: server
        image: t9kpublic/search-with-lepton:20240208
        ports:
          - containerPort: 8080
        env:
          - name: BACKEND            # 使用的搜索引擎后端
            value: "BING"            # 应为 "BING"、"GOOGLE"、"SERPER" 或 "SEARCHAPI"
          - name: OPENAI_BASE_URL    # OpenAI API 服务器（或与其兼容的服务器）的 URL
            value: "http://mixtral-8x7b/v1"
                                      # 应为 "<ADDRESS>/v1"，其中 <ADDRESS> 为 vLLM 推理服务的地址, 可通过以下命令获取：
                                      # `kubectl get mlservice <VLLM_MLSERVICE_NAME> -ojsonpath='{.status.address.url}'`
          - name: OPENAI_API_KEY
            value: "any"
          - name: LLM_MODEL          # 使用的模型名称
            value: "mixtral-8x7b"    # 应为部署 vLLM 推理服务时为 `--served-model-name` 参数设定的值
          - name: RELATED_QUESTIONS  # 是否生成关联问题并展示
            value: "false"           # 暂不支持
        envFrom:
          - secretRef:
              name: search
        resources:
          limits:
            cpu: 2
            memory: 8Gi
