apiVersion: tensorstack.dev/v1beta1
kind: MLService
metadata:
  name: codellama-7b
spec:
  # scheduler:
  #   t9kScheduler:
  #     queue: default
  default: v1
  releases:
    - name: v1
      predictor:
        minReplicas: 1
        model:
          runtime: vllm-openai
          parameters:
            MODEL_PATH: /var/lib/t9k/model
            MODEL_NAME: codellama-7b
        containersResources:
        - name: user-container
          resources:
            limits:
              cpu: 4
              memory: 64Gi
              nvidia.com/gpu: 1
        storage:
          pvc:
            name: vllm
            subPath: CodeLlama-7b-Instruct-hf
