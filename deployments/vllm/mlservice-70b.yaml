apiVersion: tensorstack.dev/v1beta1
kind: MLService
metadata:
  name: codellama-70b
spec:
  scheduler:
    t9kScheduler:
      queue: default
  default: codellama-70b
  releases:
    - name: codellama-70b
      predictor:
        minReplicas: 1
        model:
          runtime: vllm-openai-2xtp
          parameters:
            MODEL_PATH: /var/lib/t9k/model
            MODEL_NAME: codellama-70b
          modelUri: pvc://vllm/CodeLlama-70b-Instruct-hf
        containersResources:
        - name: user-container
          resources:
            limits:
              cpu: 4
              memory: 64Gi
              nvidia.com/gpu: 2
