apiVersion: tensorstack.dev/v1beta1
kind: MLServiceRuntime
metadata:
  name: vllm-openai-2xtp
spec:
  enabled: true
  template:
    spec:
      containers:
      - name: user-container
        image: t9kpublic/vllm-openai:v0.3.2
        args:
          - --model={{.MODEL_PATH}}
          - --served-model-name={{.MODEL_NAME}}
          - --trust-remote-code
          - --tensor-parallel-size=2    # 2 度张量并行
        resources:
          limits:
            cpu: 4
            memory: 64Gi
            nvidia.com/gpu: 2    # 对于 CodeLlama-70b 须为 A100 80GB
        ports:
          - containerPort: 8000
        volumeMounts:
          - mountPath: /dev/shm  # 并行需要
            name: dshm
      volumes:
        - emptyDir:
            medium: Memory
          name: dshm
