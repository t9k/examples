apiVersion: tensorstack.dev/v1beta1
kind: SimpleMLService
metadata:
  name: fastchat
spec:
  replicas: 1
  # scheduler:
  #   t9kScheduler:
  #     queue: default
  storage:
    pvc:
      name: fastchat
      subPath: Llama-2-7b-chat-hf
      containerPath: /workspace/llama2-7b-chat
  service:
    type: ClusterIP
    ports:
    - targetPort: 80
      port: 80
  custom:
    spec:
      containers:
      - name: server
        image: t9kpublic/fastchat-openai:20240227
        args:
          - "llama2-7b-chat"
        ports:
        - containerPort: 80
        resources:
          limits:
            cpu: 4
            memory: 64Gi
            nvidia.com/gpu: 1
