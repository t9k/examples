apiVersion: batch.tensorstack.dev/v1beta1
kind: DeepSpeedJob
metadata:
  name: baichuan2-evaluation-sft
spec:
  # scheduler:
  #   t9kScheduler:
  #     queue: default
  #     priority: 50
  config:
    slotsPerWorker: 1
    run:
      python:
        - ./src/train_bash.py
        - "--stage=sft"
        - "--model_name_or_path=/t9k/mnt/models/Baichuan2-7B-Base"
        - "--do_eval"
        - "--dataset=alpaca_zh"
        - "--template=default"
        - "--finetuning_type=lora"
        - "--checkpoint_dir=/t9k/mnt/output/sft-ckpts/baichuan2/7b"
        - "--output_dir=/t9k/mnt/output/sft-eval/baichuan2/7b"
        - "--per_device_eval_batch_size=8"
        - "--max_samples=100"
        - "--predict_with_generate"
  worker:
    replicas: 1
    template:
      spec:
        containers:
          - name: worker
            workingDir: /t9k/mnt/LLaMA-Efficient-Tuning
            image: t9kpublic/llama-efficient-tuning:20230918
            securityContext:
              capabilities:
                add: [ "IPC_LOCK" ]
            resources:
              requests:
                cpu: 2
                memory: 32Gi
                nvidia.com/gpu: 1
              limits:
                cpu: 4
                memory: 64Gi
                nvidia.com/gpu: 1
            volumeMounts:
              - mountPath: /t9k/mnt
                name: data
              - mountPath: /dev/shm
                name: dshm
        volumes:
          - name: data
            persistentVolumeClaim:
              claimName: llama-efficient-tuning
          - name: dshm
            emptyDir:
              medium: Memory
