apiVersion: batch.tensorstack.dev/v1beta1
kind: ColossalAIJob
metadata:
  name: colossalai-opt-benchmark
spec:
  # scheduler:
  #   t9kScheduler:
  #     queue: default
  #     priority: 50
  launcher:
    image: tsz.io/xyx/colossalai:0.3.0-opt-test1
    workingDir: /t9k/mnt/examples/colossalai/opt
  worker:
    replicas: 1
    procPerWorker: 4
    command:
      - opt_train_demo.py
      - "--model_name_or_path=/t9k/mnt/opt-*"
      - "--plugin=gemini"
      - "--batch_size=16"
      - "--mem_cap=0"
    torchArgs: []
    template:
      spec:
        restartPolicy: OnFailure
        containers:
          - image: tsz.io/xyx/colossalai:0.3.0-opt-test1
            name: worker
            resources:
              limits:
                cpu: 16
                memory: 32Gi
                nvidia.com/gpu: 4
            volumeMounts:
              - mountPath: /t9k/mnt
                name: data
        volumes:
          - name: data
            persistentVolumeClaim:
              claimName: colossalai
  runPolicy:
    cleanUpWorkers: true
