apiVersion: batch.tensorstack.dev/v1beta1
kind: ColossalAIJob
metadata:
  name: colossalai-llama
spec:
  scheduler:
    t9kScheduler:
      queue: mlperf
      priority: 50
  launcher:
    image: tsz.io/xyx/colossalai-llama:test1
    workingDir: /t9k/mnt/ColossalAI/examples/language/llama
  worker:
    replicas: 1
    procPerWorker: 4
    command:
      - pretrain.py
      - "--config=7b"
      - "--plugin=gemini"
      - "--gradient_checkpoint"
      - "--flash_attention"
    torchArgs: []
    template:
      spec:
        restartPolicy: OnFailure
        containers:
          - image: tsz.io/xyx/colossalai-llama:test1
            name: worker
            resources:
              limits:
                cpu: 16
                memory: 256Gi
                nvidia.com/gpu: 4
            volumeMounts:
              - mountPath: /t9k/mnt
                name: data
        volumes:
          - name: data
            persistentVolumeClaim:
              claimName: llama
  runPolicy:
    cleanUpWorkers: true
