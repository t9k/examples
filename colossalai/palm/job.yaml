apiVersion: batch.tensorstack.dev/v1beta1
kind: ColossalAIJob
metadata:
  name: colossalai-palm
spec:
  scheduler:
    t9kScheduler:
      queue: mlperf
      priority: 50
  launcher:
    # image: t9kpublic/colossalai:0.2.5-palm
    image: tsz.io/xyx/colossalai:0.3.0-palm-test5
    # workingDir: /workspace/ColossalAI/examples/language/palm
  worker:
    replicas: 1
    procPerWorker: 2
    command:
      - train.py
      - "--distplan=colossalai"
      # - "--dummy_data=True"
    torchArgs: []
    template:
      spec:
        restartPolicy: OnFailure
        containers:
          - image: tsz.io/xyx/colossalai:0.3.0-palm-test5
            name: worker
            resources:
              limits:
                cpu: 16
                memory: 256Gi
                nvidia.com/gpu: 2
  runPolicy:
    cleanUpWorkers: true
