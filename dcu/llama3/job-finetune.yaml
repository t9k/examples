apiVersion: batch.tensorstack.dev/v1beta1
kind: PyTorchTrainingJob
metadata:
  name: llama3-finetune
spec:
  runMode:
    debug:
      enabled: true
  replicaSpecs:
  - type: worker
    replicas: 2
    restartPolicy: OnFailure
    template:
      spec:
        containers:
        - name: llama3
          securityContext:
            privileged: true
            capabilities:
              add: ["SYS_PTRACE"]
          image: image.sourcefind.cn:5000/dcu/admin/base/pytorch:2.1.0-centos7.6-dtk24.04-py310
          env:
          - name: HIP_VISIBLE_DEVICES  # 若不设置该环境变量能看到和使用所有 DCU
            value: "0,1"
          - name: HSA_FORCE_FINE_GRAIN_PCIE
            value: "1"
          - name: USE_MIOPEN_BATCHNORM
            value: "1"
          resources:
            limits:
              cpu: 8
              memory: 64Gi
              hygon.com/dcu: 2
            requests:
              cpu: 8
              memory: 64Gi
              hygon.com/dcu: 2
          volumeMounts:
          - name: hyhal
            mountPath: /opt/hyhal/
            readOnly: true
          - name: dev-kfd
            mountPath: /dev/kfd
            readOnly: true
          - name: dev-dri
            mountPath: /dev/dri
            readOnly: true
          - name: data
            mountPath: /workspace
          - name: dshm
            mountPath: /dev/shm
        volumes:
        - name: hyhal
          hostPath:
            path: /opt/hyhal/
        - name: dev-kfd
          hostPath:
            path: /dev/kfd
        - name: dev-dri
          hostPath:
            path: /dev/dri
        - name: data
          persistentVolumeClaim:
            claimName: vllm-llama3
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: "80Gi"
